<!DOCTYPE html>
<html lang="en">
<head>
<meta charset="UTF-8">
<title>Land vs Sea — Neural Network Classifier</title>
<style>
* { box-sizing: border-box; margin: 0; padding: 0; }
body {
  background: #0d1117;
  color: #c9d1d9;
  font-family: 'Courier New', monospace;
  display: flex;
  flex-direction: column;
  align-items: center;
  padding: 24px 16px;
  gap: 14px;
  min-height: 100vh;
}
h1 { color: #58a6ff; font-size: 20px; letter-spacing: 1px; }
#status { color: #8b949e; font-size: 12px; min-height: 16px; }
.canvases { display: flex; gap: 16px; align-items: flex-start; flex-wrap: wrap; justify-content: center; }
.panel { display: flex; flex-direction: column; align-items: center; gap: 5px; }
.label { font-size: 11px; color: #6e7681; }
canvas { display: block; border: 1px solid #21262d; }
#stats { font-size: 12px; color: #8b949e; }
.controls { display: flex; gap: 10px; }
button {
  background: #21262d;
  color: #c9d1d9;
  border: 1px solid #30363d;
  padding: 7px 18px;
  cursor: pointer;
  font-family: inherit;
  font-size: 12px;
  border-radius: 5px;
  transition: background 0.1s;
}
button:hover:not(:disabled) { background: #30363d; }
button:disabled { opacity: 0.4; cursor: not-allowed; }
.ctl-select { background:#21262d; color:#c9d1d9; border:1px solid #30363d; padding:3px 6px; font-family:inherit; font-size:12px; border-radius:4px; }
.legend { display: flex; gap: 14px; font-size: 11px; color: #8b949e; }
.dot { display: inline-block; width: 10px; height: 10px; border-radius: 50%; vertical-align: middle; margin-right: 4px; }
</style>
</head>
<body>

<h1>Land vs Sea — Neural Network Classifier</h1>
<div id="status">Fetching map from Wikimedia Commons…</div>

<div class="canvases">
  <div class="panel">
    <div class="label">Training data (sampled from map)</div>
    <canvas id="mapCanvas" width="260" height="344"></canvas>
  </div>
  <div class="panel">
    <div class="label">Network prediction (updates live)</div>
    <canvas id="netCanvas" width="260" height="344"></canvas>
  </div>
  <div class="panel">
    <div class="label">Loss &amp; test accuracy</div>
    <canvas id="lossCanvas" width="150" height="344"></canvas>
  </div>
</div>

<div class="legend">
  <span><span class="dot" style="background:#00cc00"></span>Land (label = 1)</span>
  <span><span class="dot" style="background:#0066ff"></span>Sea (label = 0)</span>
</div>

<details class="explainer" style="max-width:690px; margin:0 auto; text-align:left;">
  <summary style="cursor:pointer; font-size:13px; color:#58a6ff;">How does this work?</summary>
  <div style="font-size:12px; color:#8b949e; line-height:1.6; margin-top:8px;">
    <p>
      This demo trains a small neural network to distinguish land from sea across a map
      of the British Isles (including Ireland and a sliver of northern France).
      A map image is fetched from Wikimedia Commons, and thousands of random pixel
      locations are sampled and labelled: <strong style="color:#00cc00">land (1)</strong>
      or <strong style="color:#0066ff">sea (0)</strong>, based on the pixel colour.
      The network receives only (x,&nbsp;y) coordinates as input and must learn to predict
      which side of the coastline each point falls on.
    </p>
    <p style="margin-top:8px;">
      Training uses mini-batch stochastic gradient descent (SGD) with binary cross-entropy
      loss and backpropagation. You can adjust the network architecture (depth, width,
      activation function) and training hyperparameters (learning rate, batch size) live
      in the controls below.
    </p>
    <p style="margin-top:12px; font-size:12px; color:#c9d1d9;"><strong>Terminology:</strong></p>
    <ul style="margin-top:4px; padding-left:18px;">
      <li>
        <strong>Neural network</strong> &mdash; A chain of layers of artificial neurons. Each
        neuron computes a weighted sum of its inputs, adds a bias, and passes the result
        through an activation function. By stacking layers, the network can learn complex
        non-linear boundaries &mdash; like coastlines.
      </li>
      <li style="margin-top:4px;">
        <strong>Activation function</strong> &mdash; A non-linear function applied after each
        neuron's weighted sum. Without it, stacking layers would be no more powerful than a
        single layer. <em>tanh</em> squashes values to (&minus;1,&nbsp;+1);
        <em>ReLU</em> zeroes out negatives and passes positives through unchanged.
      </li>
      <li style="margin-top:4px;">
        <strong>Forward pass</strong> &mdash; Feeding an (x,&nbsp;y) coordinate through the
        network layer by layer to produce an output between 0 (sea) and 1 (land).
      </li>
      <li style="margin-top:4px;">
        <strong>Loss (binary cross-entropy)</strong> &mdash; A measure of how wrong the
        network's predictions are. It heavily penalises confident wrong answers: predicting
        0.01 when the true label is 1 costs far more than predicting 0.4. Training aims to
        minimise this.
      </li>
      <li style="margin-top:4px;">
        <strong>Backpropagation</strong> &mdash; An algorithm that works backwards through the
        network to calculate how much each weight contributed to the loss. This gives a
        gradient &mdash; a direction to nudge each weight to reduce the error.
      </li>
      <li style="margin-top:4px;">
        <strong>Gradient descent (SGD)</strong> &mdash; The optimisation step: each weight is
        adjusted by a small amount in the direction that reduces the loss. &ldquo;Stochastic&rdquo;
        means we estimate the gradient from a random mini-batch rather than the entire dataset,
        which is much faster.
      </li>
      <li style="margin-top:4px;">
        <strong>Learning rate</strong> &mdash; How big each weight adjustment is. Too high and
        training overshoots and becomes unstable; too low and it converges very slowly.
      </li>
      <li style="margin-top:4px;">
        <strong>Batch size</strong> &mdash; The number of random samples averaged together in
        each gradient estimate. Larger batches give smoother, more reliable gradients but
        update less frequently per sample seen.
      </li>
      <li style="margin-top:4px;">
        <strong>Test set</strong> &mdash; 20% of the sampled points held back and never used
        for training. Accuracy on these unseen points shows whether the network is genuinely
        learning the coastline shape, not just memorising the training samples.
      </li>
    </ul>
    <p style="margin-top:12px; font-size:12px; color:#c9d1d9;"><strong>The three panels:</strong></p>
    <ul style="margin-top:4px; padding-left:18px;">
      <li>
        <strong>Training data</strong> (left) &mdash; The source map overlaid with sampled data
        points. <span style="color:#00cc00">Green dots</span> mark locations classified as
        land; <span style="color:#0066ff">blue dots</span> mark sea or background.
        Larger, brighter dots are training samples; smaller, fainter dots are the
        held-out test set (20% of samples, used only for evaluation).
      </li>
      <li style="margin-top:4px;">
        <strong>Network prediction</strong> (centre) &mdash; A live heatmap of the network's
        output for every pixel, evaluated on the GPU each frame.
        <span style="color:#00cc00">Green</span> = the network is confident the point is
        land (output &asymp;&nbsp;1).
        <span style="color:#0066ff">Blue</span> = confident it is sea
        (output &asymp;&nbsp;0).
        <span style="color:#ccc">White</span> = uncertain (output &asymp;&nbsp;0.5).
        As training progresses, the coloured regions sharpen and the white uncertain band
        narrows to trace the coastline.
      </li>
      <li style="margin-top:4px;">
        <strong>Loss &amp; test accuracy</strong> (right) &mdash; Two curves plotted over
        training steps.
        The <span style="color:#58a6ff">blue curve</span> shows the smoothed training loss
        (binary cross-entropy) &mdash; lower is better.
        The <span style="color:#3fb950">green curve</span> shows classification accuracy on
        the held-out test set &mdash; higher is better.
      </li>
    </ul>
    <p style="margin-top:8px;">
      When WebGL2 is available, both training (forward + backward passes) and rendering run
      entirely on the GPU via generated fragment shaders, labelled <strong>[GPU]</strong> in
      the status bar. Otherwise the demo falls back to CPU training and a lower-resolution
      Canvas 2D renderer.
    </p>
  </div>
</details>

<div id="stats">Steps: 0 | Loss: —</div>

<!-- Row 1: run controls -->
<div class="controls">
  <button id="startBtn" disabled onclick="toggle()">Start Training</button>
  <button onclick="resetNet()">Reset Network</button>
</div>

<!-- Row 2: architecture — only take effect on next Reset / Resample -->
<div class="controls">
  <span style="font-size:11px; color:#6e7681;">Architecture (on Reset):</span>
  <label style="font-size:12px; color:#8b949e; display:flex; align-items:center; gap:5px;">
    Activation
    <select id="actSelect" class="ctl-select">
      <option value="tanh">tanh</option>
      <option value="relu">ReLU</option>
    </select>
  </label>
  <label style="font-size:12px; color:#8b949e; display:flex; align-items:center; gap:5px;">
    Layers
    <select id="depthSelect" class="ctl-select">
      <option value="1">1</option>
      <option value="2">2</option>
      <option value="3" selected>3</option>
      <option value="4">4</option>
      <option value="5">5</option>
    </select>
  </label>
  <label style="font-size:12px; color:#8b949e; display:flex; align-items:center; gap:5px;">
    Width
    <select id="widthSelect" class="ctl-select">
      <option value="8">8</option>
      <option value="16">16</option>
      <option value="32" selected>32</option>
      <option value="64">64</option>
      <option value="128">128</option>
    </select>
  </label>
</div>

<!-- Row 3: training hyperparameters — live -->
<div class="controls">
  <span style="font-size:11px; color:#6e7681;">Training (live):</span>
  <label style="font-size:12px; color:#8b949e; display:flex; align-items:center; gap:5px;">
    Learning rate
    <select id="lrSelect" class="ctl-select">
      <option value="0.001">0.001</option>
      <option value="0.003">0.003</option>
      <option value="0.01">0.01</option>
      <option value="0.03">0.03</option>
      <option value="0.05" selected>0.05</option>
      <option value="0.1">0.1</option>
      <option value="0.3">0.3</option>
    </select>
  </label>
  <label style="font-size:12px; color:#8b949e; display:flex; align-items:center; gap:5px;">
    Batch size
    <select id="batchSelect" class="ctl-select">
      <option value="1">1 (SGD)</option>
      <option value="8">8</option>
      <option value="16">16</option>
      <option value="32" selected>32</option>
      <option value="64">64</option>
      <option value="128">128</option>
    </select>
  </label>
  <label style="font-size:12px; color:#8b949e; display:flex; align-items:center; gap:5px;">
    Steps/frame
    <select id="stepsSelect" class="ctl-select">
      <option value="1">1</option>
      <option value="10">10</option>
      <option value="50" selected>50</option>
      <option value="100">100</option>
      <option value="200">200</option>
      <option value="500">500</option>
    </select>
  </label>
</div>

<!-- Row 4: data -->
<div class="controls">
  <label style="font-size:12px; color:#8b949e; display:flex; align-items:center; gap:6px;">
    Samples:
    <input type="range" id="sampleSlider" min="500" max="30000" step="500" value="10000" disabled
           oninput="updateSampleLabel()"
           style="width:140px; accent-color:#58a6ff;">
    <span id="sampleLabel" style="min-width:4.5em; text-align:right;">10,000</span>
  </label>
  <button id="resampleBtn" disabled onclick="resample()">Resample</button>
</div>

<!-- Neural network lives in nn.js so it can be tested independently with node -->
<script src="nn.js"></script>
<script src="webgl-renderer.js"></script>
<script src="webgl-trainer.js"></script>
<script>

const CW = 260, CH = 344;

const mapCanvas  = document.getElementById('mapCanvas');
const mapCtx     = mapCanvas.getContext('2d');
const netCanvas  = document.getElementById('netCanvas');

// ── WebGL2 renderer (GPU-accelerated, per-pixel) with Canvas 2D fallback ──
let netCtx     = null;
let glRenderer = null;
try {
  glRenderer = new WebGLNetRenderer(netCanvas, CW, CH);
  console.log('WebGL2 renderer active — per-pixel GPU evaluation');
} catch (e) {
  console.warn('WebGL2 not available, using Canvas 2D fallback:', e.message);
  netCtx = netCanvas.getContext('2d');
}

// ── WebGL2 GPU trainer (shares GL context with the renderer) ──
let glTrainer = null;
if (glRenderer) {
  try {
    glTrainer = new WebGLTrainer(glRenderer.gl, glRenderer.vao);
    if (!glTrainer.ok) glTrainer = null;
    if (glTrainer) console.log('WebGL2 GPU training active');
  } catch (e) {
    console.warn('GPU training not available:', e.message);
    glTrainer = null;
  }
}

const lossCanvas = document.getElementById('lossCanvas');
const lossCtx    = lossCanvas.getContext('2d');

let mapPixels    = null;   // pixel data of the clean map (no dots) — reused on resample
let cleanMapData = null;   // ImageData of the clean map — restored by putImageData

let trainXs  = [];
let trainYs  = [];
let testXs   = [];
let testYs   = [];
let net      = null;
let training = false;
let stepCount    = 0;
let lossSmoothed = 0;
let lossHistory  = [];
let testAccHistory = [];
let lastTestAcc    = null;
let rafId        = null;

// ─────────────────────────────────────────────────────────────────
// Classify a pixel as land (1) or sea/background (0).
//
// The Wikimedia outline map has:
//   Land   — cream/warm colours: R is noticeably greater than B
//   Sea    — blue:               B is greater than R
//   Border — thin dark lines:    low R, G, B  (treated as sea=0)
//
// Using (R − B) as discriminant keeps it simple and robust.
// A threshold of ~20 separates cream (R−B ≈ 40–60) from blue (R−B ≈ −60).
// ─────────────────────────────────────────────────────────────────
function classifyPixel(r, g, b) {
  return (r - b > 20) ? 1 : 0;
}

// ─────────────────────────────────────────────────────────────────
// Load map from Wikimedia Commons and build training dataset
// ─────────────────────────────────────────────────────────────────
async function loadMap() {
  const statusEl = document.getElementById('status');
  try {
    // Wikimedia Commons API — origin=* enables CORS from any page
    const apiUrl =
      'https://commons.wikimedia.org/w/api.php?' +
      'action=query&titles=File:Uk_outline_map2.PNG' +
      '&prop=imageinfo&iiprop=url&format=json&origin=*';

    const resp   = await fetch(apiUrl);
    const data   = await resp.json();
    const pages  = data.query.pages;
    const imgUrl = Object.values(pages)[0].imageinfo[0].url;

    statusEl.textContent = 'Loading image…';

    const img = new Image();
    img.crossOrigin = 'anonymous';
    await new Promise((res, rej) => {
      img.onload  = res;
      img.onerror = () => rej(new Error('Image failed to load'));
      img.src = imgUrl;
    });

    // Draw onto mapCanvas (letterboxed, white background)
    mapCtx.fillStyle = '#ffffff';
    mapCtx.fillRect(0, 0, CW, CH);
    const scale = Math.min(CW / img.width, CH / img.height);
    const dw = img.width  * scale,  dh = img.height * scale;
    const dx = (CW - dw) / 2,       dy = (CH - dh)  / 2;
    mapCtx.drawImage(img, dx, dy, dw, dh);

    // Store the clean map (no dots) so resample() can restore it at any time
    cleanMapData = mapCtx.getImageData(0, 0, CW, CH);
    mapPixels    = cleanMapData.data;

    // Diagnostic: one-time log of sample pixel values to help verify threshold
    console.log('Pixel sample (px, py, r, g, b, R-B, label):');
    for (let k = 0; k < 12; k++) {
      const px = Math.floor(Math.random() * CW);
      const py = Math.floor(Math.random() * CH);
      const i  = (py * CW + px) * 4;
      const r = mapPixels[i], g = mapPixels[i+1], b = mapPixels[i+2];
      console.log(`  (${px},${py})  rgb=(${r},${g},${b})  R-B=${r-b}  label=${classifyPixel(r,g,b)}`);
    }

    document.getElementById('sampleSlider').disabled  = false;
    document.getElementById('resampleBtn').disabled   = false;
    sampleData(parseInt(document.getElementById('sampleSlider').value));

  } catch (e) {
    statusEl.textContent = 'Error: ' + e.message;
    console.error(e);
  }
}

// ─────────────────────────────────────────────────────────────────
// Render current network output on netCanvas.
//
// When WebGL2 is available the entire forward pass runs on the GPU
// per-pixel at full 260×344 resolution (89,440 evaluations/frame).
// Otherwise we fall back to the original Canvas 2D path (80×80 grid).
// ─────────────────────────────────────────────────────────────────
const GRID = 80;                      // fallback grid resolution
const tmp  = new Float64Array(2);     // reusable input buffer (fallback)

function renderNetwork() {
  if (glRenderer) {
    glRenderer.render(net);
    return;
  }

  // ── Canvas 2D fallback (identical to the original implementation) ──
  const imgData = netCtx.createImageData(CW, CH);
  const buf     = imgData.data;

  for (let gy = 0; gy < GRID; gy++) {
    for (let gx = 0; gx < GRID; gx++) {
      tmp[0] = (gx + 0.5) / GRID * 2 - 1;
      tmp[1] = (gy + 0.5) / GRID * 2 - 1;
      const p = net.forward(tmp);

      const uncertain = 1 - Math.abs(p - 0.5) * 2;
      const r = Math.round(255 * uncertain);
      const g = Math.round(102 * (1 - p) + 204 * p + 255 * uncertain);
      const b = Math.round(255 * (1 - p) + 255 * uncertain);

      const x0 = Math.floor(gx * CW / GRID),  x1 = Math.floor((gx + 1) * CW / GRID);
      const y0 = Math.floor(gy * CH / GRID),  y1 = Math.floor((gy + 1) * CH / GRID);

      for (let iy = y0; iy < y1; iy++) {
        for (let ix = x0; ix < x1; ix++) {
          const idx = (iy * CW + ix) * 4;
          buf[idx] = r;  buf[idx+1] = g;  buf[idx+2] = b;  buf[idx+3] = 255;
        }
      }
    }
  }

  netCtx.putImageData(imgData, 0, 0);
  netCtx.globalAlpha = 0.2;
  netCtx.drawImage(mapCanvas, 0, 0);
  netCtx.globalAlpha = 1;
}

// ─────────────────────────────────────────────────────────────────
// Render loss + test accuracy curves
// ─────────────────────────────────────────────────────────────────
function drawCurve(ctx, data, colour, lW, lH, pad, labelLeft, labelRight) {
  if (data.length < 2) return;
  const view = data.length > 400 ? data.slice(-400) : data;
  let hi = -Infinity, lo = Infinity;
  for (const v of view) { if (v > hi) hi = v; if (v < lo) lo = v; }
  const range = hi - lo || 0.001;

  ctx.strokeStyle = colour;
  ctx.lineWidth = 1.5;
  ctx.beginPath();
  for (let i = 0; i < view.length; i++) {
    const x = pad + (i / (view.length - 1)) * (lW - 2 * pad);
    const y = lH - pad - ((view[i] - lo) / range) * (lH - 2 * pad);
    i === 0 ? ctx.moveTo(x, y) : ctx.lineTo(x, y);
  }
  ctx.stroke();

  ctx.fillStyle = colour;
  ctx.font = '9px monospace';
  if (labelLeft)  ctx.fillText(labelLeft,  pad,          pad + 8);
  if (labelRight) ctx.fillText(labelRight, lW - pad - 20, pad + 8);
}

function renderLoss() {
  const lW = lossCanvas.width, lH = lossCanvas.height;
  const pad = 12;
  lossCtx.fillStyle = '#0d1117';
  lossCtx.fillRect(0, 0, lW, lH);

  // Blue: training loss (smoothed)
  const lastLoss = lossHistory[lossHistory.length - 1];
  drawCurve(lossCtx, lossHistory, '#58a6ff', lW, lH, pad,
    lastLoss !== undefined ? lastLoss.toFixed(3) : null, null);

  // Green: test accuracy
  const lastAcc = testAccHistory[testAccHistory.length - 1];
  drawCurve(lossCtx, testAccHistory, '#3fb950', lW, lH, pad,
    null, lastAcc !== undefined ? (lastAcc * 100).toFixed(0) + '%' : null);

  // Legend
  lossCtx.font = '9px monospace';
  lossCtx.fillStyle = '#58a6ff';
  lossCtx.fillText('loss', pad, lH - pad - 10);
  lossCtx.fillStyle = '#3fb950';
  lossCtx.fillText('acc', pad, lH - pad);
}

// ─────────────────────────────────────────────────────────────────
// (Re)sample training + test data from the stored map pixels
// ─────────────────────────────────────────────────────────────────
function sampleData(nTotal) {
  const N_TRAIN = Math.round(nTotal * 0.8);

  // Restore the clean map so old dots are erased before drawing new ones
  mapCtx.putImageData(cleanMapData, 0, 0);

  // Sample nTotal random pixels
  const allXs = [], allYs = [];
  for (let k = 0; k < nTotal; k++) {
    const px = Math.floor(Math.random() * CW);
    const py = Math.floor(Math.random() * CH);
    const i  = (py * CW + px) * 4;
    const r  = mapPixels[i], g = mapPixels[i+1], b = mapPixels[i+2];
    // Normalise pixel coordinates from [0, CW/CH) to [−1, +1].
    // Centred, unit-scale inputs make gradient descent converge much faster.
    allXs.push(new Float64Array([(px / CW) * 2 - 1, (py / CH) * 2 - 1]));
    allYs.push(classifyPixel(r, g, b));
  }

  // Fisher-Yates shuffle then split 80 / 20
  for (let i = nTotal - 1; i > 0; i--) {
    const j = Math.floor(Math.random() * (i + 1));
    [allXs[i], allXs[j]] = [allXs[j], allXs[i]];
    [allYs[i], allYs[j]] = [allYs[j], allYs[i]];
  }
  trainXs = allXs.slice(0, N_TRAIN);
  trainYs = allYs.slice(0, N_TRAIN);
  testXs  = allXs.slice(N_TRAIN);
  testYs  = allYs.slice(N_TRAIN);

  const inside = trainYs.filter(y => y === 1).length;
  console.log(`Resampled: ${nTotal} total, ${inside} inside / ${N_TRAIN - inside} outside (train)`);

  if (inside === 0) {
    document.getElementById('status').textContent =
      'ERROR: 0 "inside" labels — check console for pixel RGB values.';
    return;
  }

  // Overlay dots: training (larger, more opaque) and test (smaller, faded)
  const dotsTrain = Math.min(2000, N_TRAIN);
  for (let k = 0; k < dotsTrain; k++) {
    const cx = (trainXs[k][0] + 1) / 2 * CW;
    const cy = (trainXs[k][1] + 1) / 2 * CH;
    mapCtx.fillStyle = trainYs[k] === 1 ? 'rgba(0,204,0,0.55)' : 'rgba(0,102,255,0.28)';
    mapCtx.beginPath();
    mapCtx.arc(cx, cy, 1.5, 0, Math.PI * 2);
    mapCtx.fill();
  }
  for (let k = 0; k < testXs.length; k++) {
    const cx = (testXs[k][0] + 1) / 2 * CW;
    const cy = (testXs[k][1] + 1) / 2 * CH;
    mapCtx.fillStyle = testYs[k] === 1 ? 'rgba(0,204,0,0.2)' : 'rgba(0,102,255,0.1)';
    mapCtx.beginPath();
    mapCtx.arc(cx, cy, 1, 0, Math.PI * 2);
    mapCtx.fill();
  }

  // Upload the map (with dots) to the GPU overlay texture
  if (glRenderer) glRenderer.uploadMap(mapCanvas);

  // Reset the network and counters since the data has changed
  training = false;
  cancelAnimationFrame(rafId);
  net            = new NN(buildSizes(), document.getElementById('actSelect').value);
  if (glRenderer) glRenderer.buildShader(net.sizes, net.actName);
  if (glTrainer) {
    glTrainer.buildForArchitecture(net.sizes, net.actName);
    glTrainer.uploadWeights(net);
  }
  stepCount      = 0;
  lossSmoothed   = 0;
  lossHistory    = [];
  testAccHistory = [];
  lastTestAcc    = null;
  document.getElementById('startBtn').textContent = 'Start Training';
  document.getElementById('startBtn').disabled    = false;
  document.getElementById('stats').textContent    = 'Steps: 0 | Loss: —';
  document.getElementById('status').textContent   =
    `Ready — ${N_TRAIN.toLocaleString()} training + ${(nTotal - N_TRAIN).toLocaleString()} test samples.`;
  renderNetwork();
  renderLoss();
}

function resample() {
  sampleData(parseInt(document.getElementById('sampleSlider').value));
}

// Build the sizes array from the architecture controls, e.g. [2, 32, 32, 32, 1]
function buildSizes() {
  const depth = parseInt(document.getElementById('depthSelect').value);
  const width = parseInt(document.getElementById('widthSelect').value);
  return [2, ...Array(depth).fill(width), 1];
}

function updateSampleLabel() {
  const n = parseInt(document.getElementById('sampleSlider').value);
  document.getElementById('sampleLabel').textContent = n.toLocaleString();
}

// ─────────────────────────────────────────────────────────────────
// Test-set evaluation  (no backprop — purely forward passes)
// ─────────────────────────────────────────────────────────────────
function computeTestAccuracy() {
  let correct = 0;
  for (let i = 0; i < testXs.length; i++) {
    const pred = net.forward(testXs[i]) > 0.5 ? 1 : 0;
    if (pred === testYs[i]) correct++;
  }
  return correct / testXs.length;
}

// ─────────────────────────────────────────────────────────────────
// Training loop
// ─────────────────────────────────────────────────────────────────
const EVAL_EVERY = 200;   // test-set evaluation interval (batch steps)

function trainLoop() {
  if (!training) return;

  // Read live hyperparameters from the UI each frame
  const LR             = parseFloat(document.getElementById('lrSelect').value);
  const BATCH_SIZE     = parseInt(document.getElementById('batchSelect').value);
  const STEPS_PER_FRAME = parseInt(document.getElementById('stepsSelect').value);
  const N              = trainXs.length;

  if (glTrainer) {
    // ── GPU training path ──────────────────────────────────────
    // Run all training steps WITHOUT any readPixels calls.
    // This lets the GPU batch all draw calls with zero pipeline stalls.
    const prevStep = stepCount;
    for (let s = 0; s < STEPS_PER_FRAME; s++) {
      const bxs = [], bys = [];
      for (let b = 0; b < BATCH_SIZE; b++) {
        const k = Math.floor(Math.random() * N);
        bxs.push(trainXs[k]);
        bys.push(trainYs[k]);
      }
      glTrainer.uploadBatch(bxs, bys, BATCH_SIZE);
      glTrainer.trainStep(LR, BATCH_SIZE);
      stepCount++;
    }

    // ONE readback per frame for the loss (the last batch's output activations
    // are still in the activation texture, so readLoss is valid here).
    const loss = glTrainer.readLoss(BATCH_SIZE);
    lossSmoothed = lossSmoothed === 0 ? loss : 0.98 * lossSmoothed + 0.02 * loss;
    lossHistory.push(lossSmoothed);

    // Sync weights to CPU for test accuracy (once every EVAL_EVERY steps)
    if (stepCount % EVAL_EVERY < STEPS_PER_FRAME ||
        Math.floor(stepCount / EVAL_EVERY) !== Math.floor(prevStep / EVAL_EVERY)) {
      glTrainer.downloadWeights(net);
      lastTestAcc = computeTestAccuracy();
      testAccHistory.push(lastTestAcc);
    }

    // Render directly from the GPU weight texture (no CPU readback)
    glRenderer.renderFromTexture(glTrainer.currentWeightTexture());

  } else {
    // ── CPU training path (fallback) ───────────────────────────
    for (let s = 0; s < STEPS_PER_FRAME; s++) {
      const bxs = [], bys = [];
      for (let b = 0; b < BATCH_SIZE; b++) {
        const k = Math.floor(Math.random() * N);
        bxs.push(trainXs[k]);
        bys.push(trainYs[k]);
      }
      const loss = net.batchStep(bxs, bys, LR);
      stepCount++;
      lossSmoothed = lossSmoothed === 0 ? loss : 0.98 * lossSmoothed + 0.02 * loss;
      if (stepCount % 5 === 0) lossHistory.push(lossSmoothed);
    }

    if (stepCount % EVAL_EVERY < STEPS_PER_FRAME) {
      lastTestAcc = computeTestAccuracy();
      testAccHistory.push(lastTestAcc);
    }

    renderNetwork();
  }

  renderLoss();

  const accText = lastTestAcc !== null
    ? ` | Test acc: ${(lastTestAcc * 100).toFixed(1)}%`
    : '';
  const arch = net.sizes.join('→');
  const mode = glTrainer ? ' [GPU]' : '';
  document.getElementById('stats').textContent =
    `[${arch}]  Steps: ${stepCount.toLocaleString()} | Loss: ${lossSmoothed.toFixed(4)}${accText}${mode}`;

  rafId = requestAnimationFrame(trainLoop);
}

// ─────────────────────────────────────────────────────────────────
// Controls
// ─────────────────────────────────────────────────────────────────
function toggle() {
  const btn = document.getElementById('startBtn');
  if (training) {
    training = false;
    btn.textContent = 'Resume Training';
    cancelAnimationFrame(rafId);
    // Sync GPU weights back to CPU so test accuracy / CPU fallback stay correct
    if (glTrainer) glTrainer.downloadWeights(net);
  } else {
    if (!net) {
      net = new NN(buildSizes(), document.getElementById('actSelect').value);
      if (glRenderer) glRenderer.buildShader(net.sizes, net.actName);
      if (glTrainer) {
        glTrainer.buildForArchitecture(net.sizes, net.actName);
        glTrainer.uploadWeights(net);
      }
      renderNetwork();
    }
    training = true;
    btn.textContent = 'Pause Training';
    trainLoop();
  }
}

function resetNet() {
  training = false;
  cancelAnimationFrame(rafId);
  net            = new NN(buildSizes(), document.getElementById('actSelect').value);
  if (glRenderer) glRenderer.buildShader(net.sizes, net.actName);
  if (glTrainer) {
    glTrainer.buildForArchitecture(net.sizes, net.actName);
    glTrainer.uploadWeights(net);
  }
  stepCount      = 0;
  lossSmoothed   = 0;
  lossHistory    = [];
  testAccHistory = [];
  lastTestAcc    = null;
  document.getElementById('startBtn').textContent = 'Start Training';
  document.getElementById('stats').textContent    = 'Steps: 0 | Loss: —';
  renderNetwork();
  renderLoss();
}

loadMap();
</script>
</body>
</html>
